<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Nomenclature · UncertainData.jl documentation</title><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit">UncertainData.jl documentation</span></div><form class="docs-search" action="../../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../../">UncertainData.jl</a></li><li><span class="tocitem">Uncertain values</span><ul><li><a class="tocitem" href="../uncertainvalues_overview/">Uncertain value types</a></li><li><a class="tocitem" href="../uncertainvalues_theoreticaldistributions/">Theoretical distributions</a></li><li><a class="tocitem" href="../uncertainvalues_kde/">Kernel density estimated distributions</a></li><li><a class="tocitem" href="../uncertainvalues_fitted/">Fitted theoretical distributions</a></li><li><a class="tocitem" href="../uncertainvalues_certainvalue/">Generic constructor</a></li><li><a class="tocitem" href="../uncertainvalues_populations/">Weighted populations</a></li><li><a class="tocitem" href="../uncertainvalues_Measurements/">Generic constructor</a></li><li class="is-active"><a class="tocitem" href>Nomenclature</a><ul class="internal"><li class="toplevel"><a class="tocitem" href="#uncertainvalue_combine"><span>Combining uncertain values: the population approach</span></a></li><li class="toplevel"><a class="tocitem" href="#uncertainvalue_merge"><span>Merging uncertain values: the kernel density estimation (KDE) approach</span></a></li><li><a class="tocitem" href="#Without-weights"><span>Without weights</span></a></li><li><a class="tocitem" href="#With-weights"><span>With weights</span></a></li></ul></li><li><a class="tocitem" href="../uncertainvalues_examples/">Example 1: Uncertain values defined by theoretical distributions</a></li></ul></li><li><span class="tocitem">Uncertain datasets</span><ul><li><a class="tocitem" href="../../uncertain_datasets/uncertain_datasets_overview/">Types of uncertain value collections</a></li><li><a class="tocitem" href="../../uncertain_datasets/uncertain_index_dataset/">Uncertain index datasets</a></li><li><a class="tocitem" href="../../uncertain_datasets/uncertain_value_dataset/">Uncertain value datasets</a></li><li><a class="tocitem" href="../../uncertain_datasets/uncertain_indexvalue_dataset/">Uncertain index-value datasets</a></li><li><a class="tocitem" href="../../uncertain_datasets/uncertain_dataset/">Generic uncertain datasets</a></li></ul></li><li><span class="tocitem">Uncertain statistics</span><ul><li><input class="collapse-toggle" id="menuitem-4-1" type="checkbox"/><label class="tocitem" for="menuitem-4-1"><span class="docs-label">Core statistics</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../uncertain_statistics/core_stats/core_statistics/">Statistics on uncertain values and collections</a></li><li><a class="tocitem" href="../../uncertain_statistics/core_stats/core_statistics_point_estimates/">Point-estimate statistics</a></li><li><a class="tocitem" href="../../uncertain_statistics/core_stats/core_statistics_pairwise_estimates/">Pairwise estimates of statistics</a></li><li><a class="tocitem" href="../../uncertain_statistics/core_stats/core_statistics_datasets_single_dataset_estimates/">Statistics on single collections of uncertain data</a></li><li><a class="tocitem" href="../../uncertain_statistics/core_stats/core_statistics_datasets_pairwise_estimates/">Pairwise statistics on uncertain data collections</a></li><li><a class="tocitem" href="../../uncertain_statistics/core_stats/core_statistics_datasets/">Statistics on datasets of uncertain values</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-4-2" type="checkbox"/><label class="tocitem" for="menuitem-4-2"><span class="docs-label">Hypothesis tests</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../uncertain_statistics/hypothesistests/hypothesis_tests_overview/">Hypothesis tests for uncertain values and collections</a></li><li><a class="tocitem" href="../../uncertain_statistics/hypothesistests/one_sample_t_test/">One-sample t-test</a></li><li><a class="tocitem" href="../../uncertain_statistics/hypothesistests/equal_variance_t_test/">Equal variance t-test</a></li><li><a class="tocitem" href="../../uncertain_statistics/hypothesistests/unequal_variance_t_test/">Unequal variance t-test</a></li><li><a class="tocitem" href="../../uncertain_statistics/hypothesistests/exact_kolmogorov_smirnov_test/">Exact two-sample Kolmogorov-Smirnov test</a></li><li><a class="tocitem" href="../../uncertain_statistics/hypothesistests/approximate_twosample_kolmogorov_smirnov_test/">Approximate two-sample Kolmogorov-Smirnov test</a></li><li><a class="tocitem" href="../../uncertain_statistics/hypothesistests/jarque_bera_test/">Jarque-Bera test</a></li><li><a class="tocitem" href="../../uncertain_statistics/hypothesistests/mann_whitney_u_test/">Mann-Whitney U-test</a></li><li><a class="tocitem" href="../../uncertain_statistics/hypothesistests/anderson_darling_test/">Anderson-darling test</a></li></ul></li></ul></li><li><span class="tocitem">Sampling constraints</span><ul><li><a class="tocitem" href="../../sampling_constraints/available_constraints/">Available sampling constraints</a></li><li><a class="tocitem" href="../../sampling_constraints/constrain_uncertain_values/">Documentation</a></li><li><a class="tocitem" href="../../sampling_constraints/sequential_constraints/">Increasing/decreasing</a></li></ul></li><li><span class="tocitem">Binning</span><ul><li><a class="tocitem" href="../../binning/bin/">Binning scalar values</a></li></ul></li><li><span class="tocitem">Resampling</span><ul><li><a class="tocitem" href="../../resampling/resampling_overview/">Overview</a></li><li><a class="tocitem" href="../../resampling/resampling_uncertain_values/">Resampling uncertain values</a></li><li><a class="tocitem" href="../../resampling/resampling_uncertain_datasets/"><code>UncertainDataset</code></a></li><li><a class="tocitem" href="../../resampling/resampling_uncertain_indexvalue_datasets/"><code>UncertainIndexValueDataset</code></a></li><li><a class="tocitem" href="../../resampling/sequential/resampling_uncertaindatasets_sequential/">Is a particular constraint applicable?</a></li><li><a class="tocitem" href="../../resampling/sequential/resampling_indexvalue_sequential/">Resampling syntax</a></li><li><a class="tocitem" href="../../resampling/sequential/strictly_increasing/">Strictly increasing</a></li><li><a class="tocitem" href="../../resampling/sequential/strictly_decreasing/">Strictly decreasing</a></li><li><a class="tocitem" href="../../resampling/interpolation/interpolation/">Supported interpolations</a></li><li><a class="tocitem" href="../../resampling/interpolation/gridded/">Grids</a></li><li><a class="tocitem" href="../../resampling/resampling_schemes/resampling_schemes_uncertain_value_collections/">List of resampling schemes and their purpose</a></li><li><a class="tocitem" href="../../resampling/resampling_schemes/resampling_schemes_uncertain_indexvalue_collections/">List of resampling schemes and their purpose</a></li><li><a class="tocitem" href="../../resampling/resampling_schemes/resampling_with_schemes_uncertain_value_collections/">Resampling with schemes</a></li><li><a class="tocitem" href="../../resampling/resampling_schemes/resampling_with_schemes_uncertain_indexvalue_collections/">Resampling schemes</a></li><li><a class="tocitem" href="../../resampling/resampling_inplace/">In-place resampling</a></li></ul></li><li><span class="tocitem">Propagation of errors</span><ul><li><a class="tocitem" href="../../propagation_of_errors/propagation_of_errors/">Exact error propagation</a></li></ul></li><li><span class="tocitem">Mathematics</span><ul><li><a class="tocitem" href="../../mathematics/elementary_operations/">Elementary mathematical operations</a></li><li><a class="tocitem" href="../../mathematics/trig_functions/">Trigonometric functions</a></li></ul></li><li><span class="tocitem">Tutorials</span><ul><li><a class="tocitem" href="../../tutorials/tutorial_overview/">Regularising uncertain data</a></li><li><a class="tocitem" href="../../tutorials/tutorial_transforming_data_to_regular_grid/">Transforming uncertain data to a regular grid</a></li></ul></li><li><a class="tocitem" href="../../implementing_algorithms_for_uncertaindata/">Extending existing algorithms for uncertain data types</a></li><li><a class="tocitem" href="../../changelog/">Changelog</a></li><li><a class="tocitem" href="../../publications/">Publications/software</a></li><li><a class="tocitem" href="../../citing/">Citing</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Uncertain values</a></li><li class="is-active"><a href>Nomenclature</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Nomenclature</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/kahaaga/UncertainData.jl/blob/master/docs/src/uncertain_values/merging.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><p>Because all uncertainties are handled using a resampling approach, it is trivial to  <a href="#UncertainData.combine-Tuple{Array{AbstractUncertainValue,1}}"><code>combine</code></a> or merge uncertain values of different types into a single uncertain value.</p><h1 id="Nomenclature"><a class="docs-heading-anchor" href="#Nomenclature">Nomenclature</a><a id="Nomenclature-1"></a><a class="docs-heading-anchor-permalink" href="#Nomenclature" title="Permalink"></a></h1><p>Depending on your data, you may want to choose of one the following ways of  representing multiple uncertain values as one:</p><ul><li><a href="#uncertainvalue_combine">Combining</a>. An ensemble of uncertain    values is represented as a weighted population. This approach is nice if you want    to impose expert-opinion on the relative sampling probabilities of uncertain    values in the ensemble, but still sample from the entire supports of each of the   furnishing values. This introduces no additional approximations besides what    is already present at the moment you define your uncertain values.</li><li><a href="#uncertainvalue_merge">Merging</a>. Multiple uncertain values are merged using    a kernel density estimate to the overall distribution. This approach introduces    approximations <em>beyond</em> what is present in the uncertain values when you define them.</li></ul><h1 id="uncertainvalue_combine"><a class="docs-heading-anchor" href="#uncertainvalue_combine">Combining uncertain values: the population approach</a><a id="uncertainvalue_combine-1"></a><a class="docs-heading-anchor-permalink" href="#uncertainvalue_combine" title="Permalink"></a></h1><p><strong>Combining</strong> uncertain values is done by representing them as a weighted population of uncertain values, which is illustrated in the following example:</p><pre><code class="language-julia"># Assume we have done some analysis and have three points whose uncertainties 
# significantly overlap.
v1 = UncertainValue(Normal(0.13, 0.52))
v2 = UncertainValue(Normal(0.27, 0.42))
v3 = UncertainValue(Normal(0.21, 0.61))

# Give each value equal sampling probabilities and represent as a population
pop = UncertainValue([v1, v2, v3], [1, 1, 1])

# Let the values v1, v2 and v3 be sampled with probability ratios 1-2-3
pop = UncertainValue([v1, v2, v3], [1, 2, 3])</code></pre><p><img src="../figs/combining_uncertain_values.svg" alt/></p><p>This is not restricted to normal distributions! We can combine any type of  value in our population, even populations!</p><pre><code class="language-julia"># Consider a population of normal distributions, and a gamma distribution
v1 = UncertainValue(Normal(0.265, 0.52))
v2 = UncertainValue(Normal(0.311, 0.15))
v3 = UncertainValue([v1, v2], [2, 1])
v4 = UncertainValue(Gamma(0.5, -1))
pts = [v1, v4]
wts = [2, 1]

# New population is a nested population with unequal weights
pop = UncertainValue(pts, wts)

d1 = density(resample(pop, 20000), label = &quot;population&quot;)

d2 = plot()
density!(d2, resample(pop[1], 20000), label = &quot;v1&quot;)
density!(d2, resample(pop[2], 20000), label = &quot;v2&quot;)

plot(d1, d2, layout = (2, 1), xlabel = &quot;Value&quot;, ylabel = &quot;Density&quot;, link = :x, xlims = (-2.5, 2.5))</code></pre><p><img src="../figs/combining_uncertain_values_ex2.svg" alt/></p><p>This makes it possible treat an ensemble of uncertain values as a single uncertain value.</p><p>With equal weights, this introduces no bias beyond what is present in the data,  because resampling is done from the full supports of each of the furnishing values.  Additional information on relative sampling probabilities, however, be it informed by expert opinion or quantative estimates, is easily incorporated by adjusting  the sampling weights.</p><h1 id="uncertainvalue_merge"><a class="docs-heading-anchor" href="#uncertainvalue_merge">Merging uncertain values: the kernel density estimation (KDE) approach</a><a id="uncertainvalue_merge-1"></a><a class="docs-heading-anchor-permalink" href="#uncertainvalue_merge" title="Permalink"></a></h1><p><strong>Merging</strong> multiple uncertain values could be done by fitting a model distribution to  the values. Using any specific theoretical distribution as a model for the combined  uncertainty, however, is in general not possible, because the values may have  different types of uncertainties.</p><p>Thus, in this package, kernel kernel density estimation is used to merge multiple uncertain values.  This has the advantage that you only have to deal with a single estimate to the combined  distribution, but introduces bias because the distribution is <em>estimated</em> and the  shape of the distribution depends on the parameters of the KDE procedure.</p><h2 id="Without-weights"><a class="docs-heading-anchor" href="#Without-weights">Without weights</a><a id="Without-weights-1"></a><a class="docs-heading-anchor-permalink" href="#Without-weights" title="Permalink"></a></h2><p>When no weights are provided, the combined value is computed  by resampling each of the <code>N</code> uncertain values <code>n/N</code> times, then combining using kernel density estimation. </p><article class="docstring"><header><a class="docstring-binding" id="UncertainData.combine-Tuple{Array{AbstractUncertainValue,1}}" href="#UncertainData.combine-Tuple{Array{AbstractUncertainValue,1}}"><code>UncertainData.combine</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">combine(uvals::Vector{AbstractUncertainValue}; n = 10000*length(uvals), 
    bw::Union{Nothing, Real} = nothing)</code></pre><p>Combine multiple uncertain values into a single uncertain value. This is done by resampling each uncertain value in <code>uvals</code>, <code>n</code> times  each,  then pooling these draws together. Finally, a kernel density estimate to the final distribution is computed over those draws. </p><p>The KDE bandwidth is controlled by <code>bw</code>. By default, <code>bw = nothing</code>; in this case,  the bandwidth is determined using the <code>KernelDensity.default_bandwidth</code> function.</p><div class="admonition is-success"><header class="admonition-header">Tip</header><div class="admonition-body"><p>For very wide, close-to-normal distributions, the default bandwidth may work well.  If you&#39;re combining very peaked distributions or discrete populations, however,  you may want to lower the bandwidth significantly.</p></div></div><p><strong>Example</strong></p><pre><code class="language-julia">v1 = UncertainValue(Normal, 1, 0.3)
v2 = UncertainValue(Normal, 0.8, 0.4)
v3 = UncertainValue([rand() for i = 1:3], [0.3, 0.3, 0.4])
v4 = UncertainValue(Normal, 3.7, 0.8)
uvals = [v1, v2, v3, v4];

combine(uvals)
combine(uvals, n = 20000) # adjust number of total draws</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kahaaga/UncertainData.jl/blob/3b77d6852b0c52176baccc8219f0d8fd31abbddb/src/uncertain_values/operations/merging.jl#L1-L31">source</a></section></article><p>Weights dictating the relative contribution of each  uncertain value into the combined value can also be provided. <code>combine</code> works  with <code>ProbabilityWeights</code>, <code>AnalyticWeights</code>,  <code>FrequencyWeights</code> and the generic <code>Weights</code>. </p><p>Below shows an example of combining </p><pre><code class="language-julia">v1 = UncertainValue(rand(1000))
v2 = UncertainValue(Normal, 0.8, 0.4)
v3 = UncertainValue([rand() for i = 1:3], [0.3, 0.3, 0.4])
v4 = UncertainValue(Normal, 3.7, 0.8)
uvals = [v1, v2, v3, v4]

p = plot(title = L&quot;distributions \,\, with \,\, overlapping \,\, supports&quot;)
plot!(v1, label = L&quot;v_1&quot;, ls = :dash)
plot!(v2, label = L&quot;v_2&quot;, ls = :dot)
vline!(v3.values, label = L&quot;v_3&quot;) # plot each possible state as vline
plot!(v4, label = L&quot;v_4&quot;)

pcombined = plot(combine(uvals), title = L&quot;merge(v_1, v_2, v_3, v_4)&quot;, lc = :black, lw = 2)

plot(p, pcombined, layout = (2, 1), link = :x, ylabel = &quot;Density&quot;)</code></pre><p><img src="../figs/combine_example_noweights.png" alt/></p><h2 id="With-weights"><a class="docs-heading-anchor" href="#With-weights">With weights</a><a id="With-weights-1"></a><a class="docs-heading-anchor-permalink" href="#With-weights" title="Permalink"></a></h2><p><code>Weights</code>, <code>ProbabilityWeights</code> and  <code>AnalyticWeights</code> are functionally the same. Either  may be used depending on whether the weights are assigned subjectively or quantitatively.  With <code>FrequencyWeights</code>, it is possible to control the exact number of draws from each  uncertain value that goes into the draw pool before performing KDE.</p><h3 id="ProbabilityWeights"><a class="docs-heading-anchor" href="#ProbabilityWeights">ProbabilityWeights</a><a id="ProbabilityWeights-1"></a><a class="docs-heading-anchor-permalink" href="#ProbabilityWeights" title="Permalink"></a></h3><article class="docstring"><header><a class="docstring-binding" id="UncertainData.combine-Tuple{Array{AbstractUncertainValue,1},ProbabilityWeights}" href="#UncertainData.combine-Tuple{Array{AbstractUncertainValue,1},ProbabilityWeights}"><code>UncertainData.combine</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">combine(uvals::Vector{AbstractUncertainValue}, weights::ProbabilityWeights; 
    n = 10000*length(uvals), 
    bw::Union{Nothing, Real} = nothing)</code></pre><p>Combine multiple uncertain values into a single uncertain value. This is done by resampling each uncertain value in <code>uvals</code> proportionally to the provided  relative analytic <code>weights</code> indicating their relative importance (these are normalised by  default, so don&#39;t need to sum to 1), then pooling these draws together. Finally, a kernel  density estimate to the final distribution is computed over the <code>n</code> total draws.</p><p>Providing <code>ProbabilityWeights</code> leads to the exact same behaviour as for <code>AnalyticWeights</code>,  but may be more appropriote when, for example, weights have been determined  quantitatively. </p><p>The KDE bandwidth is controlled by <code>bw</code>. By default, <code>bw = nothing</code>; in this case,  the bandwidth is determined using the <code>KernelDensity.default_bandwidth</code> function.</p><div class="admonition is-success"><header class="admonition-header">Tip</header><div class="admonition-body"><p>For very wide, close-to-normal distributions, the default bandwidth may work well.  If you&#39;re combining very peaked distributions or discrete populations, however,  you may want to lower the bandwidth significantly.</p></div></div><p><strong>Example</strong></p><pre><code class="language-julia">v1 = UncertainValue(Normal, 1, 0.3)
v2 = UncertainValue(Normal, 0.8, 0.4)
v3 = UncertainValue([rand() for i = 1:3], [0.3, 0.3, 0.4])
v4 = UncertainValue(Normal, 3.7, 0.8)
uvals = [v1, v2, v3, v4];

# Two difference syntax options
combine(uvals, ProbabilityWeights([0.2, 0.1, 0.3, 0.2]))
combine(uvals, pweights([0.2, 0.1, 0.3, 0.2]), n = 20000) # adjust number of total draws</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kahaaga/UncertainData.jl/blob/3b77d6852b0c52176baccc8219f0d8fd31abbddb/src/uncertain_values/operations/merging.jl#L45-L84">source</a></section></article><p>For example:</p><pre><code class="language-julia">v1 = UncertainValue(UnivariateKDE, rand(4:0.25:6, 1000), bandwidth = 0.02)
v2 = UncertainValue(Normal, 0.8, 0.4)
v3 = UncertainValue([rand() for i = 1:3], [0.3, 0.3, 0.4])
v4 = UncertainValue(Gamma, 8, 0.4)
uvals = [v1, v2, v3, v4];

p = plot(title = L&quot;distributions \,\, with \,\, overlapping \,\, supports&quot;)
plot!(v1, label = L&quot;v_1: KDE \, over \, empirical \, distribution&quot;, ls = :dash)
plot!(v2, label = L&quot;v_2: Normal(0.8, 0.4)&quot;, ls = :dot)
# plot each possible state as vline
vline!(v3.values, 
    label = L&quot;v_3: \, Discrete \, population\, [1,2,3], w/ \, weights \, [0.3, 0.4, 0.4]&quot;) 
plot!(v4, label = L&quot;v_4: \, Gamma(8, 0.4)&quot;)

pcombined = plot(
    combine(uvals, ProbabilityWeights([0.1, 0.3, 0.02, 0.5]), n = 100000, bw = 0.05), 
    title = L&quot;combine([v_1, v_2, v_3, v_4], ProbabilityWeights([0.1, 0.3, 0.02, 0.5])&quot;, 
    lc = :black, lw = 2)

plot(p, pcombined, layout = (2, 1), size = (800, 600), 
    link = :x, 
    ylabel = &quot;Density&quot;,
    tickfont = font(12),
    legendfont = font(8), fg_legend = :transparent, bg_legend = :transparent)</code></pre><p><img src="../figs/combine_example_pweights.png" alt/></p><h3 id="AnalyticWeights"><a class="docs-heading-anchor" href="#AnalyticWeights">AnalyticWeights</a><a id="AnalyticWeights-1"></a><a class="docs-heading-anchor-permalink" href="#AnalyticWeights" title="Permalink"></a></h3><article class="docstring"><header><a class="docstring-binding" id="UncertainData.combine-Tuple{Array{AbstractUncertainValue,1},AnalyticWeights}" href="#UncertainData.combine-Tuple{Array{AbstractUncertainValue,1},AnalyticWeights}"><code>UncertainData.combine</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">combine(uvals::Vector{AbstractUncertainValue}, weights::AnalyticWeights; 
    n = 10000*length(uvals), 
    bw::Union{Nothing, Real} = nothing)</code></pre><p>Combine multiple uncertain values into a single uncertain value. This is done by resampling each uncertain value in <code>uvals</code> proportionally to the provided  relative probability <code>weights</code> (these are normalised by default, so don&#39;t need  to sum to 1), then pooling these draws together. Finally, a kernel density  estimate to the final distribution is computed over the <code>n</code> total draws.</p><p>Providing <code>AnalyticWeights</code> leads to the exact same behaviour as for <code>ProbabilityWeights</code>, but may be more appropriote when relative importance weights are assigned subjectively,  and not based on quantitative evidence.</p><p>The KDE bandwidth is controlled by <code>bw</code>. By default, <code>bw = nothing</code>; in this case,  the bandwidth is determined using the <code>KernelDensity.default_bandwidth</code> function.</p><div class="admonition is-success"><header class="admonition-header">Tip</header><div class="admonition-body"><p>For very wide, close-to-normal distributions, the default bandwidth may work well.  If you&#39;re combining very peaked distributions or discrete populations, however,  you may want to lower the bandwidth significantly.</p></div></div><p><strong>Example</strong></p><pre><code class="language-julia">v1 = UncertainValue(Normal, 1, 0.3)
v2 = UncertainValue(Normal, 0.8, 0.4)
v3 = UncertainValue([rand() for i = 1:3], [0.3, 0.3, 0.4])
v4 = UncertainValue(Normal, 3.7, 0.8)
uvals = [v1, v2, v3, v4];

# Two difference syntax options
combine(uvals, AnalyticWeights([0.2, 0.1, 0.3, 0.2]))
combine(uvals, aweights([0.2, 0.1, 0.3, 0.2]), n = 20000) # adjust number of total draws</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kahaaga/UncertainData.jl/blob/3b77d6852b0c52176baccc8219f0d8fd31abbddb/src/uncertain_values/operations/merging.jl#L112-L150">source</a></section></article><p>For example:</p><pre><code class="language-julia">v1 = UncertainValue(UnivariateKDE, rand(4:0.25:6, 1000), bandwidth = 0.02)
v2 = UncertainValue(Normal, 0.8, 0.4)
v3 = UncertainValue([rand() for i = 1:3], [0.3, 0.3, 0.4])
v4 = UncertainValue(Gamma, 8, 0.4)
uvals = [v1, v2, v3, v4];

p = plot(title = L&quot;distributions \,\, with \,\, overlapping \,\, supports&quot;)
plot!(v1, label = L&quot;v_1: KDE \, over \, empirical \, distribution&quot;, ls = :dash)
plot!(v2, label = L&quot;v_2: Normal(0.8, 0.4)&quot;, ls = :dot)
vline!(v3.values, label = L&quot;v_3: \, Discrete \, population\, [1,2,3], w/ \, weights \, [0.3, 0.4, 0.4]&quot;) # plot each possible state as vline
plot!(v4, label = L&quot;v_4: \, Gamma(8, 0.4)&quot;)

pcombined = plot(combine(uvals, AnalyticWeights([0.1, 0.3, 0.02, 0.5]), n = 100000, bw = 0.05), 
    title = L&quot;combine([v_1, v_2, v_3, v_4], AnalyticWeights([0.1, 0.3, 0.02, 0.5])&quot;, lc = :black, lw = 2)

plot(p, pcombined, layout = (2, 1), size = (800, 600), 
    link = :x, 
    ylabel = &quot;Density&quot;,
    tickfont = font(12),
    legendfont = font(8), fg_legend = :transparent, bg_legend = :transparent)</code></pre><p><img src="../figs/combine_example_aweights.png" alt/></p><h3 id="Generic-Weights"><a class="docs-heading-anchor" href="#Generic-Weights">Generic Weights</a><a id="Generic-Weights-1"></a><a class="docs-heading-anchor-permalink" href="#Generic-Weights" title="Permalink"></a></h3><article class="docstring"><header><a class="docstring-binding" id="UncertainData.combine-Tuple{Array{AbstractUncertainValue,1},Weights}" href="#UncertainData.combine-Tuple{Array{AbstractUncertainValue,1},Weights}"><code>UncertainData.combine</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">combine(uvals::Vector{AbstractUncertainValue}, weights::Weights; 
    n = 10000*length(uvals), 
    bw::Union{Nothing, Real} = nothing)</code></pre><p>Combine multiple uncertain values into a single uncertain value. This is done by resampling each uncertain value in <code>uvals</code> proportionally to the provided <code>weights</code>  (these are normalised by default, so don&#39;t need to sum to 1), then pooling these draws  together. Finally, a kernel density estimate to the final distribution is computed over  the <code>n</code> total draws.</p><p>Providing <code>Weights</code> leads to the exact same behaviour as for <code>ProbabilityWeights</code> and  <code>AnalyticalWeights</code>.</p><p>The KDE bandwidth is controlled by <code>bw</code>. By default, <code>bw = nothing</code>; in this case,  the bandwidth is determined using the <code>KernelDensity.default_bandwidth</code> function.</p><div class="admonition is-success"><header class="admonition-header">Tip</header><div class="admonition-body"><p>For very wide, close-to-normal distributions, the default bandwidth may work well.  If you&#39;re combining very peaked distributions or discrete populations, however,  you may want to lower the bandwidth significantly.</p></div></div><p><strong>Example</strong></p><pre><code class="language-julia">v1 = UncertainValue(Normal, 1, 0.3)
v2 = UncertainValue(Normal, 0.8, 0.4)
v3 = UncertainValue([rand() for i = 1:3], [0.3, 0.3, 0.4])
v4 = UncertainValue(Normal, 3.7, 0.8)
uvals = [v1, v2, v3, v4];

# Two difference syntax options
combine(uvals, Weights([0.2, 0.1, 0.3, 0.2]))
combine(uvals, weights([0.2, 0.1, 0.3, 0.2]), n = 20000) # adjust number of total draws</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kahaaga/UncertainData.jl/blob/3b77d6852b0c52176baccc8219f0d8fd31abbddb/src/uncertain_values/operations/merging.jl#L177-L214">source</a></section></article><p>For example:</p><pre><code class="language-julia">v1 = UncertainValue(UnivariateKDE, rand(4:0.25:6, 1000), bandwidth = 0.01)
v2 = UncertainValue(Normal, 0.8, 0.4)
v3 = UncertainValue([rand() for i = 1:3], [0.3, 0.3, 0.4])
v4 = UncertainValue(Gamma, 8, 0.4)
uvals = [v1, v2, v3, v4];

p = plot(title = L&quot;distributions \,\, with \,\, overlapping \,\, supports&quot;)
plot!(v1, label = L&quot;v_1: KDE \, over \, empirical \, distribution&quot;, ls = :dash)
plot!(v2, label = L&quot;v_2: Normal(0.8, 0.4)&quot;, ls = :dot)
# plot each possible state as vline
vline!(v3.values, 
    label = L&quot;v_3: \, Discrete \, population\, [1,2,3], w/ \, weights \, [0.3, 0.4, 0.4]&quot;) 
plot!(v4, label = L&quot;v_4: \, Gamma(8, 0.4)&quot;)

pcombined = plot(combine(uvals, Weights([0.1, 0.15, 0.1, 0.1]), n = 100000, bw = 0.02), 
    title = L&quot;combine([v_1, v_2, v_3, v_4],  Weights([0.1, 0.15, 0.1, 0.1]))&quot;, 
    lc = :black, lw = 2)

plot(p, pcombined, layout = (2, 1), size = (800, 600), 
    link = :x, 
    ylabel = &quot;Density&quot;,
    tickfont = font(12),
    legendfont = font(8), fg_legend = :transparent, bg_legend = :transparent)</code></pre><p><img src="../figs/combine_example_generic_weights.png" alt/></p><h3 id="FrequencyWeights"><a class="docs-heading-anchor" href="#FrequencyWeights">FrequencyWeights</a><a id="FrequencyWeights-1"></a><a class="docs-heading-anchor-permalink" href="#FrequencyWeights" title="Permalink"></a></h3><p>Using <code>FrequencyWeights</code>, one may specify the number of times each of the uncertain values  should be sampled to form the pooled resampled draws on which the final kernel density  estimate is performed.</p><article class="docstring"><header><a class="docstring-binding" id="UncertainData.combine-Tuple{Array{AbstractUncertainValue,1},FrequencyWeights}" href="#UncertainData.combine-Tuple{Array{AbstractUncertainValue,1},FrequencyWeights}"><code>UncertainData.combine</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">combine(uvals::Vector{AbstractUncertainValue}, weights::FrequencyWeights;
    bw::Union{Nothing, Real} = nothing)</code></pre><p>Combine multiple uncertain values into a single uncertain value. This is done by resampling each uncertain value in <code>uvals</code> according to their relative frequencies (the absolute number of draws provided by <code>weights</code>). Finally, a kernel density  estimate to the final distribution is computed over the <code>sum(weights)</code> total draws.</p><p>The KDE bandwidth is controlled by <code>bw</code>. By default, <code>bw = nothing</code>; in this case,  the bandwidth is determined using the <code>KernelDensity.default_bandwidth</code> function.</p><div class="admonition is-success"><header class="admonition-header">Tip</header><div class="admonition-body"><p>For very wide and close-to-normal distributions, the default bandwidth may work well.  If you&#39;re combining very peaked distributions or discrete populations, however,  you may want to lower the bandwidth significantly.</p></div></div><p><strong>Example</strong></p><pre><code class="language-julia">v1 = UncertainValue(Normal, 1, 0.3)
v2 = UncertainValue(Normal, 0.8, 0.4)
v3 = UncertainValue([rand() for i = 1:3], [0.3, 0.3, 0.4])
v4 = UncertainValue(Normal, 3.7, 0.8)
uvals = [v1, v2, v3, v4];

# Two difference syntax options
combine(uvals, FrequencyWeights([100, 500, 343, 7000]))
combine(uvals, pweights([1410, 550, 223, 801]))</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/kahaaga/UncertainData.jl/blob/3b77d6852b0c52176baccc8219f0d8fd31abbddb/src/uncertain_values/operations/merging.jl#L242-L273">source</a></section></article><p>For example:</p><pre><code class="language-julia">v1 = UncertainValue(UnivariateKDE, rand(4:0.25:6, 1000), bandwidth = 0.01)
v2 = UncertainValue(Normal, 0.8, 0.4)
v3 = UncertainValue([rand() for i = 1:3], [0.3, 0.3, 0.4])
v4 = UncertainValue(Gamma, 8, 0.4)
uvals = [v1, v2, v3, v4];

p = plot(title = L&quot;distributions \,\, with \,\, overlapping \,\, supports&quot;)
plot!(v1, label = L&quot;v_1: KDE \, over \, empirical \, distribution&quot;, ls = :dash)
plot!(v2, label = L&quot;v_2: Normal(0.8, 0.4)&quot;, ls = :dot)
# plot each possible state as vline
vline!(v3.values, 
    label = L&quot;v_3: \, Discrete \, population\, [1,2,3], w/ \, weights \, [0.3, 0.4, 0.4]&quot;) 
plot!(v4, label = L&quot;v_4: \, Gamma(8, 0.4)&quot;)

pcombined = plot(combine(uvals, FrequencyWeights([10000, 20000, 3000, 5000]), bw = 0.05), 
    title = L&quot;combine([v_1, v_2, v_3, v_4], FrequencyWeights([10000, 20000, 3000, 5000])&quot;, 
    lc = :black, lw = 2)

plot(p, pcombined, layout = (2, 1), size = (800, 600), 
    link = :x, 
    ylabel = &quot;Density&quot;,
    tickfont = font(12),
    legendfont = font(8), fg_legend = :transparent, bg_legend = :transparent)</code></pre><p><img src="../figs/combine_example_fweights.png" alt/></p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../uncertainvalues_Measurements/">« Generic constructor</a><a class="docs-footer-nextpage" href="../uncertainvalues_examples/">Example 1: Uncertain values defined by theoretical distributions »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> on <span class="colophon-date" title="Tuesday 16 February 2021 16:11">Tuesday 16 February 2021</span>. Using Julia version 1.5.3.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
